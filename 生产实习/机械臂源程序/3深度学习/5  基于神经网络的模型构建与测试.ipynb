{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6417b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "#import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f7b0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义卷积操作\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape#卷积核的尺寸\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))#确保卷积核滑动操作不会越界\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + h, j: j + w] * K).sum()#卷积操作\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1e6defc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):#继承了nn.Module，定义每个卷积层\n",
    "    def __init__(self, kernel_size):#初始化的时候需要提供卷积核尺寸\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "        #nn.Parameter将一个固定不可训练的tensor转换成可以训练的类型parameter，\n",
    "        # 并将这个parameter绑定到这个module里面(net.parameter()中就有这个绑定的parameter，\n",
    "        # 所以在参数优化的时候可以进行优化的)，所以经过类型转换这个self.weight变成了模型的一部分，\n",
    "        # 成为了模型中根据训练可以改动的参数了\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias#模型的正向推导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e503e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "显示卷积层处理后的输出\n",
      " tensor([[5.7277, 5.0590],\n",
      "        [3.7218, 3.0531]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "kernel_size = (2,2)#设置卷积核大小\n",
    "x =torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])#模型的输入量\n",
    "conv2d = Conv2D(kernel_size)#经过一次的卷积层处理\n",
    "print(\"显示卷积层处理后的输出\\n\",conv2d(x))#显示卷积层处理后的输出，为一个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d10368e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数均为1\n",
    "    #原X尺度为（８，８），经过x.view后，尺度为（１，１，８，８）\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维:批量和通道\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1)\n",
    "#padding控制zero-padding的数目\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c755f03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape#计算正常情况下卷积层操作后的尺度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05efb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):#pool_size为池化层大小\n",
    "    X = X.float()#x值进行浮点型转换\n",
    "    p_h, p_w = pool_size#pool_size为池化层大小\n",
    "    Y = torch.zeros(X.shape[0] - p_h + 1, X.shape[1] - p_w + 1)#池化操作后的图像存储的大小，初始时刻都是设置为０\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()#取极大值\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()#取均值\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dc5712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "极大值池化\n",
      " tensor([[4., 5.],\n",
      "        [7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "print(\"极大值池化\\n\",pool2d(X, (2, 2)))#输出显示X经过极大值池化后的输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63e5c880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均值池化\n",
      " tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"均值池化\\n\",pool2d(X, (2, 2), 'avg'))#输出显示X经过均值池化后的输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb1584c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "采用nn.MaxPool2d获得的最大池化结果\n",
      " tensor([[[[ 5.,  7.],\n",
      "          [13., 15.]]]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float).view((1, 1, 4, 4))\n",
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)#采用torch中的最大池化函数实现\n",
    "print(\"采用nn.MaxPool2d获得的最大池化结果\\n\",pool2d(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec8c7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.shape:torch.Size([1, 32, 224, 224])\n",
      "pool.shape:torch.Size([1, 32, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SelfConv(nn.Module):#构建卷积网络\n",
    "    def __init__(self):\n",
    "        super(SelfConv, self).__init__()\n",
    "        #该网络中采用了一个卷积层，一个激活函数与池化层\n",
    "        self.conv = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=(3,3),stride=1,padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)#输入的tensor先进行卷积\n",
    "        print(\"conv.shape:{}\".format(x.shape))\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        print(\"pool.shape:{}\".format(x.shape))\n",
    "\n",
    "        return x\n",
    "\n",
    "input = torch.randn(size=(1,3,224,224),dtype=torch.float32)\n",
    "model = SelfConv()#自定义模型实例化\n",
    "output = model(input)#通过自定义模型对输入变量进行运算，获得输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaf88a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
