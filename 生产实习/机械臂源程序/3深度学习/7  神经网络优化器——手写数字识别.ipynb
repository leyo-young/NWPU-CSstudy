{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c44580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8034a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数 \n",
    "image_size = 28  #图像的总尺寸28*28\n",
    "num_classes = 10  #标签的种类数\n",
    "num_epochs = 20  #训练的总循环周期\n",
    "batch_size = 64  #一个撮（批次）的大小，64张图片\n",
    "# 加载MINIST数据，如果没有下载过，就会在当前路径下新建/data子目录，并把文件存放其中\n",
    "# MNIST数据是属于torchvision包自带的数据，所以可以直接调用。\n",
    "# 在调用自己的数据的时候，我们可以用torchvision.datasets.ImageFolder或者torch.utils.data.TensorDataset来加载\n",
    "train_dataset = dsets.MNIST(root='/home/retoo/Desktop/实验/数据集/3.深度学习/7data/MNIST', download=True, #文件存放路径\n",
    "                            train=True,   #提取训练集\n",
    "                            transform=transforms.ToTensor()) \n",
    "#当找不到文件的时候，自动下载 ；将图像转化为Tensor，在加载数据的时候，就可以对图像做预处理\n",
    "# 加载测试数据集\n",
    "test_dataset = dsets.MNIST(root='/home/retoo/Desktop/实验/数据集/3.深度学习/7data/MNIST', download=True,\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "# 训练数据集的加载器，自动将数据分割成batch，顺序随机打乱\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "'''我们希望将测试数据分成两部分，一部分作为校验数据，一部分作为测试数据。\n",
    "校验数据用于检测模型是否过拟合，并调整参数，测试数据检验整个模型的工作'''\n",
    "# 首先，我们定义下标数组indices，它相当于对所有test_dataset中数据的编码\n",
    "# 然后定义下标indices_val来表示校验集数据的那些下标，indices_test表示测试集的下标\n",
    "indices = range(len(test_dataset))\n",
    "indices_val = indices[:5000]\n",
    "indices_test = indices[5000:]\n",
    "# 根据这些下标，构造两个数据集的SubsetRandomSampler采样器，它会对下标进行采样\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "# 根据两个采样器来定义加载器，注意将sampler_val和sampler_test分别赋值给了validation_loader和test_loader\n",
    "validation_loader = torch.utils.data.DataLoader(dataset =test_dataset,\n",
    "                                                batch_size = batch_size,\n",
    "                                                sampler = sampler_val\n",
    "                                               )\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          sampler = sampler_test\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5824f131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签是： 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#随便从数据集中读入一张图片，并绘制出来\n",
    "idx = 1000\n",
    "#dataset支持下标索引，其中提取出来的每一个元素为features，target格式，即属性和标签。[0]表示索引features\n",
    "muteimg = train_dataset[idx][0].numpy()\n",
    "#由于一般的图像包含rgb三个通道，而MINST数据集的图像都是灰度的，只有一个通道。因此，我们忽略通道，把图像看作一个灰度矩阵。\n",
    "#用imshow画图，会将灰度矩阵自动展现为彩色，不同灰度对应不同颜色：从黄到紫\n",
    "plt.imshow(muteimg[0,...])\n",
    "print('标签是：',train_dataset[idx][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "429a378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义卷积神经网络：4和8为人为指定的两个卷积层的厚度（feature map的数量）\n",
    "depth = [4, 8]\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 该函数在创建一个ConvNet对象的时候，即调用如下语句：net=ConvNet()，就会被调用\n",
    "        # 首先调用父类相应的构造函数\n",
    "        super(ConvNet, self).__init__()\n",
    "        # 其次构造ConvNet需要用到的各个神经模块。\n",
    "        '''注意，定义组件并没有真正搭建这些组件，只是把基本建筑砖块先找好'''\n",
    "        self.conv1 = nn.Conv2d(1, 4, 5, padding = 2) #定义一个卷积层，输入通道为1，输出通道为4，窗口大小为5，padding为2\n",
    "        self.pool = nn.MaxPool2d(2, 2) #定义一个Pooling层，一个窗口为2*2的pooling运算\n",
    "        self.conv2 = nn.Conv2d(depth[0], depth[1], 5, padding = 2) #第二层卷积，输入通道为depth[0], \n",
    "                                                                   #输出通道为depth[1]，窗口为5，padding为2\n",
    "        self.fc1 = nn.Linear(image_size // 4 * image_size // 4 * depth[1] , 512) \n",
    "                                                            #一个线性连接层，输入尺寸为最后一层立方体的平铺，输出层512个节点\n",
    "        self.fc2 = nn.Linear(512, num_classes) #最后一层线性分类单元，输入为512，输出为要做分类的类别数\n",
    "    def forward(self, x):\n",
    "        #该函数完成神经网络真正的前向运算，我们会在这里把各个组件进行实际的拼装\n",
    "        #x的尺寸：(batch_size, image_channels, image_width, image_height)\n",
    "        x = F.relu(self.conv1(x))  #第一层卷积，激活函数用ReLu，为了防止过拟合\n",
    "        #x的尺寸：(batch_size, num_filters, image_width, image_height)\n",
    "        x = self.pool(x) #第二层pooling，将图片变小\n",
    "        #x的尺寸：(batch_size, depth[0], image_width/2, image_height/2)\n",
    "        x = F.relu(self.conv2(x)) #第三层又是卷积，窗口为5，输入输出通道分别为depth[0]=4, depth[1]=8\n",
    "        #x的尺寸：(batch_size, depth[1], image_width/2, image_height/2)\n",
    "        x = self.pool(x) #第四层pooling，将图片缩小到原大小的1/4\n",
    "        #x的尺寸：(batch_size, depth[1], image_width/4, image_height/4)\n",
    "        # 将立体的特征图Tensor，压成一个一维的向量\n",
    "        # view这个函数可以将一个tensor按指定的方式重新排布。\n",
    "        # 下面这个命令就是要让x按照batch_size * (image_size//4)^2*depth[1]的方式来排布向量\n",
    "        x = x.view(-1, image_size // 4 * image_size // 4 * depth[1])\n",
    "        #x的尺寸：(batch_size, depth[1]*image_width/4*image_height/4)\n",
    "        x = F.relu(self.fc1(x)) #第五层为全链接，ReLu激活函数\n",
    "        #x的尺寸：(batch_size, 512)\n",
    "        x = F.dropout(x, training=self.training) #以默认为0.5的概率对这一层进行dropout操作，为了防止过拟合\n",
    "        x = self.fc2(x) #全链接\n",
    "        #x的尺寸：(batch_size, num_classes)\n",
    "        x = F.log_softmax(x, dim = 0) #输出层为log_softmax，即概率对数值log(p(x))。采用log_softmax可以使得后面的交叉熵计算更快\n",
    "        return x\n",
    "    def retrieve_features(self, x):\n",
    "        #该函数专门用于提取卷积神经网络的特征图的功能，返回feature_map1, feature_map2为前两层卷积层的特征图\n",
    "        feature_map1 = F.relu(self.conv1(x)) #完成第一层卷积\n",
    "        x = self.pool(feature_map1)  # 完成第一层pooling\n",
    "        feature_map2 = F.relu(self.conv2(x)) #第二层卷积，两层特征图都存储到了feature_map1, feature_map2中\n",
    "        return (feature_map1, feature_map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf6317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(1565), 5000)\n",
      "训练周期: 0 [0/60000 (0%)]\tLoss: 2.298913\t训练正确率: 18.75%\t校验正确率: 31.30%\n"
     ]
    }
   ],
   "source": [
    "net = ConvNet()  # 新建一个卷积神经网络的实例，此时ConvNet的__init__函数就会被自动调用\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Loss函数的定义，交叉熵\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.001,betas=(0.9, 0.99)) #定义优化器\n",
    "# optimizer = optim.SGD(net.parameters(),lr=0.001, momentum=0.9)\n",
    "optimzier = torch.optim.RMSprop(net.parameters(), lr=0.001, alpha=0.9)\n",
    "# optimzier= torch.optim.SGD(net_SGD.parameters(), lr=0.001)\n",
    "record = []  # 记录准确率等数值的容器\n",
    "weights = []  # 每若干步就记录一次卷积核\n",
    "\n",
    "def rightness(output, target):\n",
    "    pred=output.data.max(dim=1,keepdim=True)[1]\n",
    "    return  pred.eq(target.data.view_as(pred)).cpu().sum(),len(target)\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_rights = []  # 记录训练数据集准确率的容器\n",
    "\n",
    "    ''' 下面的enumerate是构造一个枚举器的作用。就是我们在对train_loader做循环迭代的时候，enumerate会自动吐出一个数字指示我们循环了几次\n",
    "     这个数字就被记录在了batch_idx之中，它就等于0，1.txt，2，……\n",
    "     train_loader每迭代一次，就会吐出来一对数据data和target，分别对应着一个batch中的手写数字图，以及对应的标签。'''\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # 针对容器中的每一个批进行循环\n",
    "        data, target = data.clone().requires_grad_(True), target.clone().detach()\n",
    "        # data为一批图像，target为一批标签\n",
    "        #x.data（x.detach()） 返回和 x 的相同数据 tensor, 这个新的tensor和原来的tensor（即x）是共用数据的，一者改变，另一者也会跟着改变，且require s_grad = False\n",
    "        #不同点： x.data 不能被 autograd 追踪求微分，即使被改了也能错误求导，而x.detach()则不行\n",
    "        net.train()  # 给网络模型做标记，标志说模型正在训练集上训练，\n",
    "        # 这种区分主要是为了打开关闭net的training标志，从而决定是否运行dropout\n",
    "\n",
    "        output = net(data)  # 神经网络完成一次前馈的计算过程，得到预测输出output\n",
    "        loss = criterion(output, target)  # 将output与标签target比较，计算误差\n",
    "        optimzier.zero_grad()  # 清空梯度\n",
    "        loss.backward()  # 反向传播\n",
    "        optimzier.step()  # 一步随机梯度下降算法\n",
    "        right = rightness(output, target)  # 计算准确率所需数值，返回数值为（正确样例数，总样本数）\n",
    "        train_rights.append(right)  # 将计算结果装到列表容器train_rights中\n",
    "\n",
    "        if batch_idx % 100 == 0:  # 每间隔100个batch执行一次打印等操作\n",
    "\n",
    "            net.eval()  # 给网络模型做标记，标志说模型在训练集上训练\n",
    "            val_rights = []  # 记录校验数据集准确率的容器\n",
    "\n",
    "            '''开始在校验数据集上做循环，计算校验集上面的准确度'''\n",
    "            for (data, target) in validation_loader:\n",
    "                data, target = data.clone().requires_grad_(True), target.clone().detach()\n",
    "                output = net(data)  # 完成一次前馈计算过程，得到目前训练得到的模型net在校验数据集上的表现\n",
    "                right = rightness(output, target)  # 计算准确率所需数值，返回正确的数值为（正确样例数，总样本数）\n",
    "                val_rights.append(right)\n",
    "\n",
    "            # 分别计算在目前已经计算过的测试数据集，以及全部校验集上模型的表现：分类准确率\n",
    "            # train_r为一个二元组，分别记录目前已经经历过的所有训练集中分类正确的数量和该集合中总的样本数，\n",
    "            # train_r[0]/train_r[1.txt]就是训练集的分类准确度，同样，val_r[0]/val_r[1.txt]就是校验集上的分类准确度\n",
    "            train_r = (sum([tup[0] for tup in train_rights]), sum([tup[1] for tup in train_rights]))\n",
    "            # val_r为一个二元组，分别记录校验集中分类正确的数量和该集合中总的样本数\n",
    "            val_r = (sum([tup[0] for tup in val_rights]), sum([tup[1] for tup in val_rights]))\n",
    "            # 打印准确率等数值，其中正确率为本训练周期Epoch开始后到目前撮的正确率的平均值\n",
    "            print(val_r)\n",
    "            print('训练周期: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t训练正确率: {:.2f}%\\t校验正确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx * batch_size, len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader),\n",
    "                loss.data,\n",
    "                       100. * train_r[0].numpy() / train_r[1],\n",
    "                       100. * val_r[0].numpy() / val_r[1]))\n",
    "\n",
    "            # 将准确率和权重等数值加载到容器中，以方便后续处理\n",
    "            record.append((100 - 100. * train_r[0] / train_r[1], 100 - 100. * val_r[0] / val_r[1]))\n",
    "            # weights记录了训练周期中所有卷积核的演化过程。net.conv1.weight就提取出了第一层卷积核的权重\n",
    "            # clone的意思就是将weight.data中的数据做一个拷贝放到列表中，否则当weight.data变化的时候，列表中的每一项数值也会联动\n",
    "            '''这里使用clone这个函数很重要'''\n",
    "            weights.append([net.conv1.weight.data.clone(), net.conv1.bias.data.clone(),\n",
    "                            net.conv2.weight.data.clone(), net.conv2.bias.data.clone()])\n",
    "\n",
    "\n",
    "# 绘制实验结果，打印测试集上的准确度\n",
    "plt.plot([i[0] for i in record],label='Train')\n",
    "plt.plot([i[1] for i in record],label='Validation')\n",
    "# right_rate\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160b849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
