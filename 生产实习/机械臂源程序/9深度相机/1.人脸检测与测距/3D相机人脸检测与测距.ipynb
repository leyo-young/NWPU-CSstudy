{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d69db9-5bbd-4471-bc86-933c117b9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyrealsense2.align'>\n",
      "object_x: 342\n",
      "object_y: 131\n",
      "The camera is facing an object mean  740  mm away.\n",
      "object_x: 343\n",
      "object_y: 219\n",
      "The camera is facing an object mean  751  mm away.\n",
      "object_x: 342\n",
      "object_y: 220\n",
      "The camera is facing an object mean  753  mm away.\n",
      "object_x: 342\n",
      "object_y: 220\n",
      "The camera is facing an object mean  748  mm away.\n",
      "object_x: 342\n",
      "object_y: 219\n",
      "The camera is facing an object mean  756  mm away.\n",
      "object_x: 343\n",
      "object_y: 219\n",
      "The camera is facing an object mean  746  mm away.\n",
      "object_x: 342\n",
      "object_y: 218\n",
      "The camera is facing an object mean  744  mm away.\n",
      "object_x: 342\n",
      "object_y: 219\n",
      "The camera is facing an object mean  744  mm away.\n",
      "object_x: 341\n",
      "object_y: 219\n",
      "The camera is facing an object mean  749  mm away.\n",
      "object_x: 341\n",
      "object_y: 218\n",
      "The camera is facing an object mean  753  mm away.\n",
      "object_x: 341\n",
      "object_y: 219\n",
      "The camera is facing an object mean  755  mm away.\n",
      "object_x: 340\n",
      "object_y: 214\n",
      "The camera is facing an object mean  766  mm away.\n",
      "object_x: 338\n",
      "object_y: 204\n",
      "The camera is facing an object mean  772  mm away.\n",
      "object_x: 342\n",
      "object_y: 208\n",
      "The camera is facing an object mean  776  mm away.\n",
      "object_x: 346\n",
      "object_y: 206\n",
      "The camera is facing an object mean  761  mm away.\n"
     ]
    }
   ],
   "source": [
    "# %load 3D相机人脸检测与测距.py\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import serial\n",
    "import random\n",
    "\n",
    "data_ser = serial.Serial(\"/dev/user_robot\", 115200, timeout=5)  # 云台串口，设备波特率为115200\n",
    "global object_x#检测物体中心点X的坐标\n",
    "global object_y#检测物体中心点Y的坐标\n",
    "#云台控制\n",
    "def bus_bjdj(value):  # 步进电机位置控制（id，位置）0-315mm\n",
    "    ddata = [0xFF,0xFE,0x02,0x01,0x00, 0x01, 0x46,0x00,0x0D,0x0A]\n",
    "    ddata[5] = value\n",
    "    data_ser.write(ddata)#串口发送数据\n",
    "    time.sleep(0.1)\n",
    "if __name__ == '__main__':\n",
    "    bus_bjdj(0x5A)#控制云台抬起摄像头\n",
    "    pipeline = rs.pipeline()  # 创建一个管道\n",
    "    config = rs.config()  # Create a config并配置要流式传输的管道。\n",
    "    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)#使用选定的流参数\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "    # Start streaming 开启流\n",
    "    pipeline.start(config)\n",
    "    align = rs.align(rs.stream.color) #深度图像向彩色对齐\n",
    "    print(type(align))\n",
    "    global object_x\n",
    "    global object_y\n",
    "    object_x = 320  # 修改成检测目标的中心点即可\n",
    "    object_y = 240\n",
    "    try:\n",
    "        while True:\n",
    "            frames = pipeline.wait_for_frames()  # 等待开启通道\n",
    "            aligned_frames = align.process(frames)  # 将深度框和颜色框对齐\n",
    "            depth_frame = aligned_frames.get_depth_frame()  # 获得对齐后的帧数深度数据(图)\n",
    "            color_frame = aligned_frames.get_color_frame()  # 获得对齐后的帧数颜色数据(图)\n",
    "            img_color = np.asanyarray(color_frame.get_data())  # 把图像像素转化为数组\n",
    "            img_depth = np.asanyarray(depth_frame.get_data())  # 把图像像素转化为数组\n",
    "            # Apply colormap on depth image (image must be converted to 8-bit per pixel first) 在深度图上用颜色渲染\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(img_depth, alpha=0.03), cv2.COLORMAP_JET)\n",
    "            #人脸检测中点\n",
    "            image = img_color.copy()\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)#转灰度\n",
    "            face_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")#加载人脸检测模型数据\n",
    "            faces = face_detector.detectMultiScale(gray, 1.1, 5)#检测人脸\n",
    "            for x, y, w, h in faces:\n",
    "                cv2.rectangle(img_color, (x, y), (x + w, y + h), (0, 0, 255), 2)#根据检测的数据画矩形框\n",
    "                object_x=round(x+w/2)\n",
    "                object_y=round(y+h/2)\n",
    "                print(\"object_x:\",object_x)\n",
    "                print(\"object_y:\", object_y)\n",
    "                # 获取目标框内的物体距离，并进行均值滤波\n",
    "                depth_points = []\n",
    "                for j in range(50):#取50个点的随机数测量平均深度值\n",
    "                    rand_x = random.randint(x, x + w)\n",
    "                    rand_y = random.randint(y, y + h)\n",
    "                    depth_point = round(depth_frame.get_distance(rand_x, rand_y)*1000, 2)\n",
    "                    if depth_point != 0:\n",
    "                        depth_points.append(depth_point)\n",
    "                depth_object = np.mean(depth_points)\n",
    "                if depth_object >= 300:\n",
    "                    print(\"The camera is facing an object mean \", int(depth_object), \" mm away.\")\n",
    "                else:\n",
    "                    print(\"The camera is facing an object mean <300 mm away.\")\n",
    "                cv2.circle(img_color, (int(object_x), int(object_y)), 8, [0, 0, 255], thickness=-1)#画出中心点\n",
    "                cv2.putText(img_color, \"Distance:\" + str(round(depth_object)) + \"mm\", (5, 40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, [255, 0, 255])#写出距离值\n",
    "            image_new = np.hstack((depth_colormap,img_color ))#图像拼接在一起\n",
    "            cv2.imshow(\"RealSense:\",image_new)\n",
    "            key = cv2.waitKey(10)\n",
    "            if key & 0xFF == ord('q') or key == 27:\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "    finally:\n",
    "        pipeline.stop()#关闭流\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0607c-01b8-42cc-a7f4-9f3ef961b354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
