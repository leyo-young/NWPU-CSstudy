{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c697d7b7-b802-4f7c-89d3-11fac7d98ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 行人目标检测.py\n",
    "#!/usr/bin/env python3\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "class my_nanodet():\n",
    "    def __init__(self, input_shape=320, prob_threshold=0.6, iou_threshold=0.6, model_path='./nanodet.onnx', clsname_path='./coco.names'):\n",
    "        with open(clsname_path, 'rt') as f:\n",
    "            self.classes = f.read().rstrip('\\n').split('\\n')\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.strides = (8, 16, 32)\n",
    "        self.input_shape = (input_shape, input_shape)\n",
    "        self.reg_max = 7\n",
    "        self.prob_threshold = prob_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.project = np.arange(self.reg_max + 1)\n",
    "        self.mean = np.array([103.53, 116.28, 123.675], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.std = np.array([57.375, 57.12, 58.395], dtype=np.float32).reshape(1, 1, 3)\n",
    "        self.net = cv2.dnn.readNet(model_path)\n",
    "        self.mlvl_anchors = []\n",
    "        for i in range(len(self.strides)):\n",
    "            anchors = self._make_grid((int(self.input_shape[0] / self.strides[i]), int(self.input_shape[1] / self.strides[i])), self.strides[i])\n",
    "            self.mlvl_anchors.append(anchors)\n",
    "        print('模型初始化完成！')\n",
    "\n",
    "    def _make_grid(self, featmap_size, stride):\n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = np.arange(0, feat_w) * stride\n",
    "        shift_y = np.arange(0, feat_h) * stride\n",
    "        xv, yv = np.meshgrid(shift_x, shift_y)\n",
    "        xv = xv.flatten()\n",
    "        yv = yv.flatten()\n",
    "        cx = xv + 0.5 * (stride-1)\n",
    "        cy = yv + 0.5 * (stride - 1)\n",
    "        return np.stack((cx, cy), axis=-1)\n",
    "\n",
    "    def softmax(self,x, axis=1):\n",
    "        x_exp = np.exp(x)\n",
    "        # 如果是列向量，则axis=0\n",
    "        x_sum = np.sum(x_exp, axis=axis, keepdims=True)\n",
    "        s = x_exp / x_sum\n",
    "        return s\n",
    "\n",
    "    def _normalize(self, img):  \n",
    "        img = img.astype(np.float32)\n",
    "        img = (img - self.mean) / self.std\n",
    "        return img\n",
    "\n",
    "    def resize_image(self, srcimg, keep_ratio=True):\n",
    "        top, left, newh, neww = 0, 0, self.input_shape[0], self.input_shape[1]\n",
    "        if keep_ratio and srcimg.shape[0] != srcimg.shape[1]:\n",
    "            hw_scale = srcimg.shape[0] / srcimg.shape[1]\n",
    "            if hw_scale > 1:\n",
    "                newh, neww = self.input_shape[0], int(self.input_shape[1] / hw_scale)\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                left = int((self.input_shape[1] - neww) * 0.5)\n",
    "                img = cv2.copyMakeBorder(img, 0, 0, left, self.input_shape[1] - neww - left, cv2.BORDER_CONSTANT,\n",
    "                                         value=0)  # add border\n",
    "            else:\n",
    "                newh, neww = int(self.input_shape[0] * hw_scale), self.input_shape[1]\n",
    "                img = cv2.resize(srcimg, (neww, newh), interpolation=cv2.INTER_AREA)\n",
    "                top = int((self.input_shape[0] - newh) * 0.5)\n",
    "                img = cv2.copyMakeBorder(img, top, self.input_shape[0] - newh - top, 0, 0, cv2.BORDER_CONSTANT, value=0)\n",
    "        else:\n",
    "            img = cv2.resize(srcimg, self.input_shape, interpolation=cv2.INTER_AREA)\n",
    "        return img, newh, neww, top, left\n",
    "\n",
    "    def detect(self, srcimg):\n",
    "        img, newh, neww, top, left = self.resize_image(srcimg)\n",
    "        img = self._normalize(img)\n",
    "        blob = cv2.dnn.blobFromImage(img)  #将输入图片进行数据处理，符合模型输入的要求\n",
    "        # 将图像数据加载到网络模型\n",
    "        self.net.setInput(blob)\n",
    "        # 模型中进行前向预测，得到输出结果\n",
    "        outs = self.net.forward(self.net.getUnconnectedOutLayersNames())\n",
    "\n",
    "        det_bboxes, det_conf, det_classid = self.post_process(outs)\n",
    "        drawimg = srcimg.copy()\n",
    "        ratioh,ratiow = srcimg.shape[0]/newh,srcimg.shape[1]/neww\n",
    "        for i in range(det_bboxes.shape[0]):\n",
    "            xmin, ymin, xmax, ymax = max(int((det_bboxes[i,0] - left) * ratiow), 0), max(int((det_bboxes[i,1] - top) * ratioh), 0), min(\n",
    "                int((det_bboxes[i,2] - left) * ratiow), srcimg.shape[1]), min(int((det_bboxes[i,3] - top) * ratioh), srcimg.shape[0])\n",
    "            self.drawPred(drawimg, det_classid[i], det_conf[i], xmin, ymin, xmax, ymax)\n",
    "        return drawimg\n",
    "\n",
    "    def post_process(self, preds):\n",
    "        cls_scores, bbox_preds = preds[::2], preds[1::2]\n",
    "        det_bboxes, det_conf, det_classid = self.get_bboxes_single(cls_scores, bbox_preds, 1, rescale=False)\n",
    "        return det_bboxes.astype(np.int32), det_conf, det_classid\n",
    "\n",
    "    def get_bboxes_single(self, cls_scores, bbox_preds, scale_factor, rescale=False):\n",
    "        mlvl_bboxes = []\n",
    "        mlvl_scores = []\n",
    "        for stride, cls_score, bbox_pred, anchors in zip(self.strides, cls_scores, bbox_preds, self.mlvl_anchors):\n",
    "            if cls_score.ndim==3:\n",
    "                cls_score = cls_score.squeeze(axis=0)\n",
    "            if bbox_pred.ndim==3:\n",
    "                bbox_pred = bbox_pred.squeeze(axis=0)\n",
    "            bbox_pred = self.softmax(bbox_pred.reshape(-1, self.reg_max + 1), axis=1)\n",
    "            bbox_pred = np.dot(bbox_pred, self.project).reshape(-1,4)\n",
    "            bbox_pred *= stride\n",
    "            nms_pre = 1000\n",
    "            if nms_pre > 0 and cls_score.shape[0] > nms_pre:\n",
    "                max_scores = cls_score.max(axis=1)\n",
    "                topk_inds = max_scores.argsort()[::-1][0:nms_pre]\n",
    "                anchors = anchors[topk_inds, :]\n",
    "                bbox_pred = bbox_pred[topk_inds, :]\n",
    "                cls_score = cls_score[topk_inds, :]\n",
    "            bboxes = self.distance2bbox(anchors, bbox_pred, max_shape=self.input_shape)\n",
    "            mlvl_bboxes.append(bboxes)\n",
    "            mlvl_scores.append(cls_score)\n",
    "\n",
    "        mlvl_bboxes = np.concatenate(mlvl_bboxes, axis=0)\n",
    "        if rescale:\n",
    "            mlvl_bboxes /= scale_factor\n",
    "        mlvl_scores = np.concatenate(mlvl_scores, axis=0)\n",
    "\n",
    "        bboxes_wh = mlvl_bboxes.copy()\n",
    "        bboxes_wh[:, 2:4] = bboxes_wh[:, 2:4] - bboxes_wh[:, 0:2]  ####xywh\n",
    "        classIds = np.argmax(mlvl_scores, axis=1)\n",
    "        confidences = np.max(mlvl_scores, axis=1)  ####max_class_confidence\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(bboxes_wh.tolist(), confidences.tolist(), self.prob_threshold, self.iou_threshold)\n",
    "        if len(indices)>0:\n",
    "            mlvl_bboxes = mlvl_bboxes[indices[:, 0]]\n",
    "            confidences = confidences[indices[:, 0]]\n",
    "            classIds = classIds[indices[:, 0]]\n",
    "            return mlvl_bboxes, confidences, classIds\n",
    "        else:\n",
    "            return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    def distance2bbox(self, points, distance, max_shape=None):\n",
    "        x1 = points[:, 0] - distance[:, 0]\n",
    "        y1 = points[:, 1] - distance[:, 1]\n",
    "        x2 = points[:, 0] + distance[:, 2]\n",
    "        y2 = points[:, 1] + distance[:, 3]\n",
    "        if max_shape is not None:\n",
    "            x1 = np.clip(x1, 0, max_shape[1])\n",
    "            y1 = np.clip(y1, 0, max_shape[0])\n",
    "            x2 = np.clip(x2, 0, max_shape[1])\n",
    "            y2 = np.clip(y2, 0, max_shape[0])\n",
    "        return np.stack([x1, y1, x2, y2], axis=-1)\n",
    "\n",
    "#画框\n",
    "    def drawPred(self, frame, classId, conf, left, top, right, bottom):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), thickness=4)\n",
    "\n",
    "        label = '%.2f' % conf\n",
    "        label = '%s:%s' % (self.classes[classId], label)\n",
    "        print('检测结果为：',self.classes[classId],conf)\n",
    "        # 在图像的顶点处显示检测结果\n",
    "        labelSize, baseLine = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        top = max(top, labelSize[1])\n",
    "        cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), thickness=2)\n",
    "        return frame\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # 模型初始化\n",
    "    net = my_nanodet()\n",
    "    # 相机采图\n",
    "    pipeline = rs.pipeline()\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "\n",
    "    pc = rs.pointcloud()\n",
    "    connect_device = []\n",
    "    for d in rs.context().devices:\n",
    "        print('Found device: ',\n",
    "              d.get_info(rs.camera_info.name), ' ',\n",
    "              d.get_info(rs.camera_info.serial_number))\n",
    "        if d.get_info(rs.camera_info.name).lower() != 'platform camera':\n",
    "            connect_device.append(d.get_info(rs.camera_info.serial_number))\n",
    "    # 成流\n",
    "    config.enable_device(connect_device[0])\n",
    "    profile = pipeline.start(config)\n",
    "    # (对其流)\n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)     # 设置为其他类型的流,意思是我们允许深度流与其他流对齐\n",
    "    while True:\n",
    "        # 等待一组连贯的帧:深度和颜色\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)  # 将深度框和颜色框对齐\n",
    "        depth_frame = aligned_frames.get_depth_frame()\n",
    "        color_frame = aligned_frames.get_color_frame()\n",
    "        if not depth_frame or not color_frame:\n",
    "            continue\n",
    "        # 将图像转换为numpy数组\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        (H, W) = color_image.shape[:2]\n",
    "        #将图片放到模型中训练\n",
    "        srcimg = net.detect(color_image)\n",
    "        winName = 'people'\n",
    "        cv2.imshow(winName, srcimg)\n",
    "        key = cv2.waitKey(1)\n",
    "        # Press esc or 'q' to close the image window\n",
    "        if key & 0xFF == ord('q') or key == 27:\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
